#!/usr/bin/env sh

#v# kagami v0.6.3 â€” static microblog processor
#v# (c) 2022 microsounds <https://github.com/microsounds>, GPLv3+
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 3
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Suite 500, Boston, MA  02110-1335, USA.

#
#
## OPTION FLAGS
#
#h# usage: kagami [options]
#h#  clean            Recursively deletes all output files that would have
#h#                   been created under normal operation.
#h#  -h, --help       Displays help message.
#h#  -v, --version    Displays version information.
unset clean
for f in "$1"; do case "$f" in
	-*[vh]*)
		sel=$(echo "$f" | tr -d '-' | cut -c 1)
		egrep "^#$sel" < "$0" | sed 's/[^ ]* //'
		exit 1;;
	clean) clean=1;;
esac; done

#
#
## GLOBAL / ERROR CHECKING
#
mode='error'
mesg_st() { printf '%s%s' "${mode:+[$mode] }" "$@"; } # for overwriting
mesg() { mesg_st "$@"; printf '\n'; }
quit() { mesg "$@, exiting." 1>&2; exit 1; }
require() { command -v "$1" > /dev/null; }

# announce created files with progress indicator
# sets global variable SPINNER indicating pid of current spinner
set_spinner() {
	mode=' '; mesg_st "$1";
	printf '\r'
	while :; do
		for f in '\' '|' '/' '-'; do
			mode="$f"; mesg_st;
			printf '\r'
			sleep 0.05
		done
	done &
	SPINNER="$!"
}
clear_spinner() { kill "$SPINNER"; printf '\r\33[K'; }

# define valid kagami {MACRO} identifier regex
mformat='[A-Za-z0-9_]+'

# define non-colliding single-byte sed delimiter
# this character CANNOT appear in expanded macros or processed
# markdown documents under any circumstances
delim='' # non-printable literal 0x01

# require GNU date from GNU coreutils
# assert 64-bit date support
date --version | fgrep -q 'GNU' || quit "GNU date is required"
date -d "1970-01-01 UTC $(echo '2^31' | bc) seconds" > /dev/null 2>&1 ||
	( mode='!';
		mesg '32-bit GNU date will not support dates beyond Jan 19, 2038'; )

# select markdown utility
# prefer cmark-gfm, fallback to standard cmark if not found.
cmark='cmark-gfm'; opts='--smart'
if require "$cmark"; then
	# enable github flavored markdown extensions and flags
	for f in --unsafe --table-prefer-style-attributes \
		footnotes table strikethrough autolink; do
		case $f in
			-*) opts="$opts $f";;
			*) opts="$opts -e $f"
		esac
	done
else
	cmark="${cmark%-*}"
	require "$cmark" || quit "$cmark not installed"
fi
markdown="$cmark $opts"

# any dir or parent thereof that contains the following dirs will
# be considered the working directory.
# all operations are relative to this dir.
config='.kagami'  # configuration directory
source='.src'     # source markdown documents

# kagami will run only if the 2 dirs described above actually exist,
# even if they're empty. kagami tries to be fault-tolerant when convenient.
# Missing files aren't an issue, kagami will only complain about it.
working_dir="$PWD"
while [ ! -z "$working_dir" ] && [ ! -d "$working_dir/$config" ]; do
	working_dir="${working_dir%/*}"
done
[ ! -z "$working_dir" ] ||
	quit "Directory '$config' not found in this or any parent dir up to /"

source_dir="$working_dir/$source"
[ -d "$source_dir" ] ||
	quit "Markdown documents expected in '$source_dir'"

config_dir="$working_dir/$config"
for f in head.htm tail.htm macros; do
	[ -f "$config_dir/$f" ] ||
		( mode='!'; mesg "Expected to find '$config_dir/$f'"; )
done

unset mode

#
#
## FILE OPERATIONS
#
# compare file mtime in a peculiar way
# if either file doesn't exist, assume first file is always newer
is_newer() (
	res="$(find "$1" -newer "$2" 2> /dev/null)" || return 0
	[ ! -z "$res" ]
)

# returns relative filename of newest file in a directory
# if dir is empty, or doesn't exist, or is actually a file, return nothing
newest_file() (
	file="$(ls -1t "$1" | head -n 1)"
	# ls echos your filename if it's a file
	[ "$1" = "$file" ] && unset file
	echo "$file"
)

# clean mode
# announce filenames before deleting
clean_file() (
	[ -f "$1" ] && ( mode='-'; mesg "$1"; )
	rm -rf "$1"
)

#
#
## DATE ROUTINES
#
# human readable date used for indexing
# eg. January 2020
simple_date() (
	[ ! -z "$1" ] || [ "$1" -eq "$1" ] 2> /dev/null || return 1
	date -d "1970-01-01 UTC $1 seconds" '+%B %Y'
)

# default fallback date function used by CREATED, UPDATED
# override with DATE_FUNCTION
# eg. 1 Jan 2020
full_date() (
	[ ! -z "$1" ] || [ "$1" -eq "$1" ] 2> /dev/null || return 1
	date -d "1970-01-01 UTC $1 seconds" '+%d %b %Y'
)

# RFC 5322 timestamps used by RSS feeds
rfc_date() (
	[ ! -z "$1" ] || [ "$1" -eq "$1" ] 2> /dev/null || return 1
	date -d "1970-01-01 UTC $1 seconds" -R
)

#
#
## RSS FEED ROUTINES
#
# generate RSS feed headers
rss_init() (
	if [ ! -z "$SITE_HOSTNAME" ]; then
		# guess permalink to RSS feed
		feed_link="$SITE_HOSTNAME/${RSS_FEED#"$working_dir/"}"

		# generate RSS 2.0 feed only if user-provided SITE_HOSTNAME is set
		cat <<- EOF > "$RSS_FEED"
			<?xml version="1.0" encoding="utf-8"?>
			<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
			<channel>
			<ttl>1</ttl>
			<generator>$VERSION</generator>
			<docs>http://blogs.law.harvard.edu/tech/rss</docs>
			<atom:link href="$feed_link" rel="self" type="application/rss+xml"/>
			<link>$SITE_HOSTNAME</link>
		EOF

		# user provided macros SITE_TITLE and SITE_DESCRIPTION
		# recommended but not required
		[ ! -z "$SITE_TITLE" ] && \
			echo "<title>$SITE_TITLE</title>" >> "$RSS_FEED"
		[ ! -z "$SITE_DESCRIPTION" ] && \
			echo "<description>$SITE_DESCRIPTION</description>" >> "$RSS_FEED"
	else
		( mode='!'; mesg 'Skipped RSS feed because SITE_HOSTNAME is unset.'; )
	fi
)

# finalize RSS feed
# set lastBuildDate to latest pubDate found
rss_close() (
	if [ -f "$RSS_FEED" ]; then
		cat <<- EOF >> "$RSS_FEED"
			</channel>
			</rss>
		EOF

		# insert lastBuildDate before items as per RSS 2.0 spec in-place
		latest="$(fgrep '<pubDate>' | sed -E 's,</?\w+>,,g' \
			| xargs -I '{}' date -d '{}' '+%s' | sort -nr | head -n 1 \
			| xargs -I '{}' date -d '1970-01-01 UTC {} seconds' -R)" < "$RSS_FEED"
		{	rm "$RSS_FEED"
			sed "/^<channel>/a <lastBuildDate>$latest</lastBuildDate>" > "$RSS_FEED"
		} < "$RSS_FEED"
		( mode='+'; mesg "$RSS_FEED"; )
	fi
)

#
#
## MARKDOWN ROUTINES
#
# note: impure function
# generate a markdown index of files in the same directory sorted by
# descending creation date, files without timestamps will not show up
# on this list
# markdown linked URLs are relative to index.md for now
# indexed files are also appended to the RSS feed if it exists
md_index() (
	cd "$1" || return
	for f in *.md; do
		curr="$(cat "$f")" # load file only once
		title="$(echo "$curr" | md_title "$f")";

		# accept first 2 timestamps found
		# parse timestamps using variable expansion
		# formatting significant, makes use of newline literals
		timest="$(echo "$curr" | md_timestamp | head -n 2)"
		for g in mtime crtime; do
			sel="${timest#*
}"
			# human readable
			eval "$g=\"$(simple_date $sel)\""
			# keep timestamps in *_raw
			eval "${g}_raw=\"$sel\""
			timest="${timest%%
"$sel"}"
		done
		# if document has no mtime
		[ "$mtime" = "$crtime" ] && unset mtime mtime_raw
		unset timest

		# crtime forms the basis for index sorting
		if [ ! -z "$crtime" ]; then
			list="$list\n$crtime_raw\t* [$title]($f) ---"
			list="$list _$crtime${mtime:+ <span style=\"font-size: 85%;\">(updated $mtime)</span>}_"

			# append to RSS feed if it exists
			# guess permalink to current file
			# use mtime as pubDate if set
			if [ ! -z "$SITE_HOSTNAME" ] && [ -f "$RSS_FEED" ]; then
				link="${PWD#"$source_dir"}/${f%.*}.htm"
				link="$SITE_HOSTNAME/${link#/}"
				cat <<- EOF >> "$RSS_FEED"
					<item>
						<title>$title</title>
						<description>
							<![CDATA[$(echo "$curr" | md_summary)]]>
							<![CDATA[<br/>Read more at <a href="$link">$link</a>]]>
						</description>
						<link>$link</link>
						<guid isPermaLink="true">$link</guid>
						<pubDate>$(rfc_date "${mtime_raw:-$crtime_raw}")</pubDate>
					</item>
				EOF
			fi
		fi
	done
	# remove trailing newline and sort by crtime
	printf '%s\n\n' '<div class="index">'
	echo "$list" | grep . | sort -nr | cut -f2
	printf '\n%s\n' '</div>'
)

# sanitize stray syntax from input
# specifically, markdown headings, markdown inline images,
# kagami macros and HTML inline syntax
md_strip() (
	sed -E \
		-e 's/^# //' \
		-e 's/!\[\w+\]//g' \
		-e "s/\{$mformat\}//g" \
		-e 's/<[^>]*>//g'
)

# get page title from first <h1> '# heading' in markdown file
# (optional) accepts filename argument as fallback
md_title() (
	title="$(grep '^# ' | md_strip | head -n 1)"
	fallback="${1##*/}"       # filename as fallback
	fallback="${fallback%.*}" # strip extension
	echo "${title:-$fallback}"
)

# return sorted newline delimited list of unix timestamps derived from page
# comments containing well formed GNU date compatible date strings in the form
# '<!--word xxxx/xx/xx-->'
md_timestamp() (
	st='^<!-- *'; ed=' *-->$'
	grep "$st" | sed -e "s/$st//" -e "s/$ed//" \
		| while read -r date; do
		# return valid dates only
		date -d "${date#* }" '+%s' 2> /dev/null
	done | sort -n
)

# generate plaintext blurb from first 80 words
# remove headings and whitespace, extract plaintext from raw HTML
md_summary() (
	sed -E '/^#/d' | grep . | $markdown \
		| md_strip | tr -s ' ' '\n' | head -n 80 | tr '\n' ' '
	printf '%s' '[..]'
)

# create attribute identifier name from input
# strip markdown/HTML syntax extra hard for use in identifiers
md_toc_id() (
	md_strip | tr -cd 'A-Za-z0-9-_:. ' | tr ' ' '-'
)

# generate anchor id-linked markdown bullet list
# from from all headings in markdown document
md_toc() (
	IFS='
'
	# cmark aggressively wraps some inline <div> elements with <p> tags
	printf '%s\n\n' '<div class="toc">'
	echo 'Table of Contents'
	while read -r line; do
		case "$line" in
			\#*)
				# convert h1-6 markdown headings to
				# their equivalent as a tab indented bullet list
				prefix="$(echo "${line% *}" | tr -cd '#')"
				prefix="$(tr '\0' '	' < /dev/zero \
					| dd count=1 bs=$((${#prefix} - 1)) 2> /dev/null)"
				heading="${line#* }"
				printf '%s* [%s](#%s)\n' \
					"$prefix" "$(echo "$heading" | md_strip)" \
					"$(echo "$heading" | md_toc_id)";;
		esac
	done
	printf '\n%s\n' '</div>'
)

# append anchor id to every heading in markdown document
md_toc_anchor() (
	IFS='
'
	while read -r line; do
		case "$line" in
			\#*)
				heading="${line#* }"
				printf '%s<span id="%s"></span>\n' \
					"$line" "$(echo "$heading" | md_toc_id)";;
			*) printf '%s\n' "$line"
		esac
	done
)

#
#
## MACROS
#
# global environment macros
export VERSION="$("$0" --version | grep '^kagami')"
export DOC_ROOT="$working_dir"
export DATE_FUNCTION='full_date' # fallback date function

# import user-provided macros
[ -f "$config_dir/macros" ] && . "$config_dir/macros"

#
#
## MAIN ROUTINES
#
# report on global state
[ -z "$clean" ] && for f in DOC_ROOT SITE_HOSTNAME; do
	eval "val=\${$f}"
	( mode="$f"; mesg "${val:-(unset)}"; )
done

# initialize RSS feed if not in clean mode
RSS_FEED="$working_dir/rss.xml"
[ -z "$clean" ] && rss_init || clean_file "$RSS_FEED"
trap 'rss_close' 0 1 2 3 6 15

# get the filename of the newest file in the config directory
config_newest="$config_dir/$(newest_file "$config_dir")"

# go through directory recursively, all paths must be absolute
process_dir() (
	mode='error' # sanity check
	case "$1" in [!/]*) quit "'$1' not an absolute path";; esac
	! cd "$1" 2> /dev/null && quit "Could not enter '$1'" ||
	for file in *; do
		# recurse subdirectory
		[ -d "$1/$file" ] && process_dir "$1/$file"

		# generate matching output file for every markdown file found
		# file path rewritten to land outside of source dir
		case "$file" in *.md);; *) continue; esac
		orig="$1/$file"
		new="${orig%.*}.htm"
		new="$working_dir${new#$source_dir}"

		# clean mode
		# delete output files that would have been generated under
		# normal operation if they exist
		if [ ! -z "$clean" ]; then
			clean_file "$new"
			continue
		fi

		# subdirs are created if they don't exist
		new_dir="${new%/*}"
		[ -d "$new_dir" ] ||
			( mode='/'; mesg "created $new_dir"; mkdir -p "$new_dir"; )

		# index files have a dynamic index and are always refreshed
		unset index
		case "$orig" in *index.md) touch "$orig"; index=1;; esac

		# generate an output file if stale or non-existent
		# non-existent files are implicitly older and will be created
		# if config dir has been modified, all files are considered stale
		if is_newer "$orig" "$new" || is_newer "$config_newest" "$new"; then

			# load markdown document only once
			set_spinner "$new"
			tmp="$(cat "$orig")"

			# generate local environment macros
			timest="$(echo "$tmp" | md_timestamp | head -n 2)"
			TITLE="$(echo "$tmp" | md_title "$new")"
			CREATED="$($DATE_FUNCTION $(echo "$timest" | head -n 1))"
			UPDATED="$($DATE_FUNCTION $(echo "$timest" | tail -n +2 | head -n 1))"

			# optional macro TOC
			# generate markdown table of contents
			# escape newlines to preserve during macro expansion
			echo "$tmp" | fgrep -q '{TOC}' && {
				TOC="$(echo "$tmp" | md_toc | $markdown \
					| sed -E 's/$/\\\\n/g' | tr -d '\n')"
			}

			# { concat; } | { macro; } > output
			# process entire file in memory to reduce disk latency
			{
				# concatenate page content
				cat "$config_dir/head.htm"
				echo '<!--{VERSION}-->'

				# append inline anchors to markdown document
				# cmark aggressively escapes macro identifiers in inline links
				echo "$tmp" | md_toc_anchor \
					| $markdown | sed -e 's/%7B/{/g' -e 's/%7D/}/g'

				# regenerate index for this directory
				# append to RSS feed
				if [ ! -z "$index" ]; then
					md_index "${orig%/*}" | $markdown
				fi
				cat "$config_dir/tail.htm"
			} | {
				# macro expansion
				# convert inline links to other markdown files
				script='s,\.md,\.htm,g;'

				# queue macro substitutions into a single sed invocation
				tmp="$(cat)"
				for ext in \
					$(echo "$tmp" | egrep -o "\{$mformat\}" | sort | uniq); do
					# strip braces
					int="${ext#?}"; int="${int%?}"
					# interpret inline macros as shell variables
					eval "int=\${$int}"
					# replace macro with contents of shell variable if set
					script="${script}s${delim}${ext}${delim}${int}${delim}g;"
				done
				# strip newlines before expansion
				echo "$tmp" | sed -e "$(echo "$script" | tr -d '\n')"
			} > "$new" && \
					clear_spinner && ( mode='+'; mesg "$new"; )
		fi
	done
)

process_dir "$source_dir"
